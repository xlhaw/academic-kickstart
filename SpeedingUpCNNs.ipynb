{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeedingUpCNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xlhaw/academic-kickstart/blob/master/SpeedingUpCNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_wZqs-xMKNE",
        "colab_type": "text"
      },
      "source": [
        "# Speeding up Convolutional Neural Networks\n",
        "\n",
        ">>>![](https://cdn-images-1.medium.com/max/716/1*FjzcTRoe-R680V0hOwYo5A.png)\n",
        "\n",
        ">>>>> From “Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition” paper\n",
        "\n",
        "This notebook is meant to support [this](https://medium.com/@alexburlacu1996/speeding-up-neural-networks-convolutions-240beac5e30f) blog post with concrete examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoraimCbPrg2",
        "colab_type": "code",
        "outputId": "25ff6293-cf00-4766-bb34-943865b658f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras as _k\n",
        "\n",
        "print(f\"Keras version: {_k.__version__}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras version: 2.2.4\n",
            "Tensorflow version: 1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOhEalmhUbe",
        "colab_type": "text"
      },
      "source": [
        "## Models\n",
        "\n",
        "The notebook explains how different methods of speeding up the convolutional layers work and their effect on a LeNet inspired model and an All-CNN-C model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3DPMsrOobzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Conv2D, Activation, Lambda, Conv3D, BatchNormalization\n",
        "\n",
        "\n",
        "ExpandDimension = lambda axis: Lambda(lambda x: K.expand_dims(x, axis))\n",
        "SqueezeDimension = lambda axis: Lambda(lambda x: K.squeeze(x, axis))\n",
        "\n",
        "# Layers\n",
        "def simple_factorized_conv(filters, kernel, *args, **kwargs):\n",
        "    kwargs[\"activation\"] = None\n",
        "    def __inner(inp):\n",
        "        cnn1 = Conv2D(filters, (kernel[0], 1), *args, **kwargs)(inp)\n",
        "        cnn2 = Conv2D(filters, (1, kernel[1]), *args, **kwargs)(cnn1)\n",
        "        \n",
        "        return cnn2\n",
        "\n",
        "    return __inner\n",
        "  \n",
        "def cp_decomposed_conv(filters, kernel, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Beware, it doesn't work! It's just an aproximate demostration of how\n",
        "    CP decomposition should be implemented. The issue is in the dimension matching.\n",
        "    If you found the solution, feel free to comment it, either in the blogpost or here.\n",
        "    You'll get full credit for your finding.\n",
        "    \"\"\"\n",
        "    kwargs[\"activation\"] = None\n",
        "    rank = filters // 2\n",
        "    d = kernel[0]\n",
        "    def __inner(inp):\n",
        "        first    = Conv2D(rank, kernel_size=(1, 1), **kwargs)(inp)\n",
        "        \n",
        "        expanded = ExpandDimension(axis=1)(first)\n",
        "        mid1     = Conv3D(rank, kernel_size=(d, 1, 1), **kwargs)(expanded)\n",
        "        mid2     = Conv3D(rank, kernel_size=(1, d, 1), **kwargs)(mid1)\n",
        "        squeezed = SqueezeDimension(axis=1)(mid2)\n",
        "        \n",
        "        last     = Conv2D(filters,  kernel_size=(1, 1), **kwargs)(squeezed)\n",
        "        \n",
        "        return last\n",
        "\n",
        "    return __inner\n",
        "\n",
        "def bn_relu(layer):\n",
        "    def __inner(*args, **kwargs):\n",
        "        l = layer(*args, **kwargs)\n",
        "        bn = BatchNormalization()(l)\n",
        "        act = Activation(\"relu\")(bn)\n",
        "        \n",
        "        return act # courtesy to Jiun-Kuei Jung\n",
        "\n",
        "    return __inner\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puaMMZX9Y_Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Dense, Dropout, Conv2D, SeparableConv2D,\n",
        "    MaxPool2D, Flatten, GlobalAveragePooling2D\n",
        ")\n",
        "\n",
        "class BaseExampleModel:\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        \"\"\"\n",
        "        :convtype: used as a flag to easily switch the Convolution layer implementation\n",
        "        \"\"\"\n",
        "        self.conv_layer = lambda *args, **kwargs: {\n",
        "                              \"std\": bn_relu(Conv2D(*args, **kwargs)),\n",
        "                              \"sep\": bn_relu(SeparableConv2D(*args, **kwargs)),\n",
        "                              \"cp\" : bn_relu(cp_decomposed_conv(*args, **kwargs)),\n",
        "                              \"fac\": bn_relu(simple_factorized_conv(*args, **kwargs))\n",
        "                          }[conv_type]\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        \"\"\"\n",
        "        :inp: a reference to the Keras Input layer, to easily switch the input size\n",
        "              and even the way data is fed into network\n",
        "              (via standard Keras methods or via TF Dataset API)\n",
        "        :nb_classes: for the final Dense layer\n",
        "        \"\"\"\n",
        "        NotImplemented\n",
        "\n",
        "class AllCNNLike(BaseExampleModel):\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        super().__init__(conv_type=conv_type)\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        conv1 = self.conv_layer(96, (3, 3), padding=\"same\")(inp)\n",
        "        conv2 = self.conv_layer(96, (3, 3), padding=\"same\")(conv1)\n",
        "        \n",
        "        conv3 = bn_relu(Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2)))(conv2)\n",
        "        \n",
        "        conv4 = self.conv_layer(192, (3, 3), padding=\"same\")(conv3)\n",
        "        conv5 = self.conv_layer(192, (3, 3), padding=\"same\")(conv4)\n",
        "        \n",
        "        conv6 = bn_relu(Conv2D(192, (3, 3), padding=\"same\", strides=(2, 2)))(conv5)\n",
        "        \n",
        "        conv7 = bn_relu(Conv2D(192, (3, 3), padding=\"same\"))(conv6)\n",
        "        conv8 = bn_relu(Conv2D(192, (1, 1), padding=\"same\"))(conv7)\n",
        "        conv9 = bn_relu(Conv2D(nb_classes, (1, 1), padding=\"same\"))(conv8)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(conv9)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)\n",
        "      \n",
        "class WiderAllCNNLike(BaseExampleModel):\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self, conv_type=\"std\"):\n",
        "        super().__init__(conv_type=conv_type)\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        conv1 = self.conv_layer(192, (3, 3), padding=\"same\")(inp)\n",
        "        \n",
        "        conv2 = bn_relu(Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2)))(conv1)\n",
        "        \n",
        "        conv3 = self.conv_layer(384, (3, 3), padding=\"same\")(conv2)\n",
        "        \n",
        "        conv4 = bn_relu(Conv2D(128, (3, 3), padding=\"same\", strides=(2, 2)))(conv3)\n",
        "        \n",
        "        conv5 = bn_relu(Conv2D(256, (3, 3), padding=\"same\"))(conv4)\n",
        "        conv6 = bn_relu(Conv2D(nb_classes, (1, 1), padding=\"same\"))(conv5)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(conv6)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNR22H8hwdgY",
        "colab_type": "code",
        "outputId": "f8ab3605-71c6-4cd8-f212-d58bcc3138b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_data(pair):\n",
        "    x, y = pair\n",
        "    return x / 255., to_categorical(y)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = map(preprocess_data, cifar100.load_data())\n",
        "\n",
        "train_gen = ImageDataGenerator().flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "test_gen = ImageDataGenerator().flow(x_test, y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 9s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfgyShr7e3Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "from keras.optimizers import  SGD\n",
        "from keras.layers import Input\n",
        "\n",
        "def main(conv_type=\"std\", verbose=False, net_type=\"simple\"):\n",
        "    inp = Input(shape=(32, 32, 3))\n",
        "    net = {\n",
        "        \"simple\": AllCNNLike(conv_type=conv_type).make(inp, nb_classes=100),\n",
        "        \"wide\": WiderAllCNNLike(conv_type=conv_type).make(inp, nb_classes=100)\n",
        "    }[net_type]\n",
        "\n",
        "    net.compile(SGD(lr=0.01, decay=0.001, momentum=0.8), \"categorical_crossentropy\",\n",
        "                 metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "    if verbose:\n",
        "        print(net.summary())\n",
        "\n",
        "    net.fit_generator(train_gen, steps_per_epoch=50000 // BATCH_SIZE, epochs=5, verbose=verbose)\n",
        "    loss, acc, topk_acc = net.evaluate_generator(test_gen, steps=10000 // BATCH_SIZE)\n",
        "\n",
        "    print(f\"Accuracy: {acc}, Top5 Accuracy {topk_acc} and Loss {loss}.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwq5PiO54oi",
        "colab_type": "text"
      },
      "source": [
        "## Standard Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7BIk1qgw6kg",
        "colab_type": "code",
        "outputId": "514d6932-2fee-437f-877b-72643c1cb78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1561
        }
      },
      "source": [
        "# Run it!\n",
        "main(\"std\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 192)       166080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 192)       331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,392,500\n",
            "Trainable params: 1,389,804\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 36s 23ms/step - loss: 3.9801 - categorical_accuracy: 0.1236 - top_k_categorical_accuracy: 0.3421\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 32s 20ms/step - loss: 3.5620 - categorical_accuracy: 0.2003 - top_k_categorical_accuracy: 0.4800\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 33s 21ms/step - loss: 3.3145 - categorical_accuracy: 0.2480 - top_k_categorical_accuracy: 0.5488\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 32s 21ms/step - loss: 3.1350 - categorical_accuracy: 0.2808 - top_k_categorical_accuracy: 0.5931\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 32s 20ms/step - loss: 2.9940 - categorical_accuracy: 0.3082 - top_k_categorical_accuracy: 0.6263\n",
            "Accuracy: 0.31860977564102566, Top5 Accuracy 0.6302083333333334 and Loss 2.879887064297994.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn1fY9pR6BaE",
        "colab_type": "text"
      },
      "source": [
        "## Simply Factorized Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvAky1jN6Nno",
        "colab_type": "code",
        "outputId": "fdf74af8-4b98-4155-f657-f9962ec5e4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1577
        }
      },
      "source": [
        "# You know what to do ;)\n",
        "main(\"fac\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 96)        960       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 32, 32, 96)        27744     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 16, 16, 192)       55488     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 16, 16, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,280,756\n",
            "Trainable params: 1,278,060\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 3.9850 - categorical_accuracy: 0.1210 - top_k_categorical_accuracy: 0.3358\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 3.5857 - categorical_accuracy: 0.1913 - top_k_categorical_accuracy: 0.4695\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 3.3498 - categorical_accuracy: 0.2377 - top_k_categorical_accuracy: 0.5347\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 3.1737 - categorical_accuracy: 0.2701 - top_k_categorical_accuracy: 0.5797\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 3.0434 - categorical_accuracy: 0.2964 - top_k_categorical_accuracy: 0.6101\n",
            "Accuracy: 0.2537118780096308, Top5 Accuracy 0.5485553772070626 and Loss 3.147618059553266.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r59tSSuw6SXo",
        "colab_type": "text"
      },
      "source": [
        "## Dephwise Separable Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_AEPNq6WpU",
        "colab_type": "code",
        "outputId": "4fb37c08-647b-42a3-90cf-fed56ff45090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1434
        }
      },
      "source": [
        "# Push that button!\n",
        "main(\"sep\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_13 (Separab (None, 32, 32, 96)        411       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_14 (Separab (None, 32, 32, 96)        10176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_15 (Separab (None, 16, 16, 192)       19488     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_16 (Separab (None, 16, 16, 192)       38784     \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 8, 8, 192)         331968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 8, 8, 192)         37056     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 8, 8, 100)         19300     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 877,583\n",
            "Trainable params: 874,887\n",
            "Non-trainable params: 2,696\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 4.0143 - categorical_accuracy: 0.1191 - top_k_categorical_accuracy: 0.3295\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.6362 - categorical_accuracy: 0.1863 - top_k_categorical_accuracy: 0.4560\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.4172 - categorical_accuracy: 0.2265 - top_k_categorical_accuracy: 0.5158\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.2630 - categorical_accuracy: 0.2552 - top_k_categorical_accuracy: 0.5586\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.1424 - categorical_accuracy: 0.2812 - top_k_categorical_accuracy: 0.5869\n",
            "Accuracy: 0.27758828250401285, Top5 Accuracy 0.5734349919743178 and Loss 3.089213261060883.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P-8Gjxw9f-W",
        "colab_type": "text"
      },
      "source": [
        "## Wide Standard Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDeWv06C9e2e",
        "colab_type": "code",
        "outputId": "12c3870d-cc2b-425a-d663-a0314f81522b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1111
        }
      },
      "source": [
        "main(\"std\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 32, 32, 192)       5376      \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_104 (Activation)  (None, 32, 32, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_93 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_105 (Activation)  (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 16, 16, 384)       332160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_94 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "activation_106 (Activation)  (None, 16, 16, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_95 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_107 (Activation)  (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_96 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_108 (Activation)  (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_97 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_109 (Activation)  (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_13  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_110 (Activation)  (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,271,508\n",
            "Trainable params: 1,269,196\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 33s 21ms/step - loss: 3.9585 - categorical_accuracy: 0.1320 - top_k_categorical_accuracy: 0.3578\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 31s 20ms/step - loss: 3.5738 - categorical_accuracy: 0.2030 - top_k_categorical_accuracy: 0.4833\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 3.3524 - categorical_accuracy: 0.2475 - top_k_categorical_accuracy: 0.5483\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 3.1939 - categorical_accuracy: 0.2795 - top_k_categorical_accuracy: 0.5872\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 3.0858 - categorical_accuracy: 0.3003 - top_k_categorical_accuracy: 0.6110\n",
            "Accuracy: 0.3113964686998395, Top5 Accuracy 0.6158707865168539 and Loss 2.9824192068550026.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9HrLDw89wIC",
        "colab_type": "text"
      },
      "source": [
        "## Wide Separable Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63TmL7DN91yq",
        "colab_type": "code",
        "outputId": "276a2b77-66b9-4f36-ec9f-43e96511a1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1111
        }
      },
      "source": [
        "main(\"sep\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_23 (Separab (None, 32, 32, 192)       795       \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 32, 32, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_24 (Separab (None, 16, 16, 384)       38112     \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 16, 16, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_8 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 972,879\n",
            "Trainable params: 970,567\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 4.0293 - categorical_accuracy: 0.1147 - top_k_categorical_accuracy: 0.3230\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.7112 - categorical_accuracy: 0.1781 - top_k_categorical_accuracy: 0.4411\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.5124 - categorical_accuracy: 0.2183 - top_k_categorical_accuracy: 0.5028\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 29s 18ms/step - loss: 3.3756 - categorical_accuracy: 0.2446 - top_k_categorical_accuracy: 0.5386\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 3.2749 - categorical_accuracy: 0.2637 - top_k_categorical_accuracy: 0.5626\n",
            "Accuracy: 0.27879213483146065, Top5 Accuracy 0.5764446227929374 and Loss 3.1429175584312428.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMQuI3t493z0",
        "colab_type": "text"
      },
      "source": [
        "## Wide Simply Factorized Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P92aWTwo92vo",
        "colab_type": "code",
        "outputId": "2a04223e-5919-4226-f328-61cad32136ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1183
        }
      },
      "source": [
        "main(\"fac\", net_type=\"wide\", verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 192)       1920      \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 32, 32, 192)       110784    \n",
            "_________________________________________________________________\n",
            "batch_normalization_70 (Batc (None, 32, 32, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 32, 32, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 16, 16, 96)        165984    \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 16, 16, 384)       110976    \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 16, 16, 384)       442752    \n",
            "_________________________________________________________________\n",
            "batch_normalization_72 (Batc (None, 16, 16, 384)       1536      \n",
            "_________________________________________________________________\n",
            "activation_81 (Activation)   (None, 16, 16, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 8, 8, 128)         442496    \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_75 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 1,600,404\n",
            "Trainable params: 1,598,092\n",
            "Non-trainable params: 2,312\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 52s 33ms/step - loss: 3.9616 - categorical_accuracy: 0.1298 - top_k_categorical_accuracy: 0.3542\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 3.5735 - categorical_accuracy: 0.2049 - top_k_categorical_accuracy: 0.4832\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 3.3399 - categorical_accuracy: 0.2505 - top_k_categorical_accuracy: 0.5497\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 3.1804 - categorical_accuracy: 0.2816 - top_k_categorical_accuracy: 0.5894\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 3.0554 - categorical_accuracy: 0.3078 - top_k_categorical_accuracy: 0.6207\n",
            "Accuracy: 0.29253611556982345, Top5 Accuracy 0.5900882825040128 and Loss 3.0202260208742193.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFVdAkF0dkO-",
        "colab_type": "text"
      },
      "source": [
        "## Failures aside, now a good architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM158WQhdjdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdequatelyDesignedAllCNNLike:\n",
        "    \"\"\"\n",
        "    isnpired from https://arxiv.org/abs/1412.6806\n",
        "    namely All-CNN-C\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def make(self, inp, nb_classes):\n",
        "        # the chunk below can be represented as a single layer with 5x5 kernels\n",
        "        conv1 = Conv2D(96, (3, 3), padding=\"same\")(inp)\n",
        "        bn1   = BatchNormalization()(conv1)\n",
        "        act1  = Activation(\"relu\")(bn1)\n",
        "        conv2 = Conv2D(96, (3, 3), padding=\"same\")(act1)\n",
        "        bn2   = BatchNormalization()(conv2)\n",
        "        act2  = Activation(\"relu\")(bn2)\n",
        "        \n",
        "        conv3 = Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2))(act2)\n",
        "        bn3   = BatchNormalization()(conv3)\n",
        "        act3  = Activation(\"relu\")(bn3)\n",
        "        \n",
        "        conv4 = SeparableConv2D(256, (3, 3), padding=\"same\")(act3)\n",
        "        bn4   = BatchNormalization()(conv4)\n",
        "        act4  = Activation(\"relu\")(bn4)\n",
        "        \n",
        "        conv5 = Conv2D(192, (3, 3), padding=\"same\", strides=(2, 2))(act4)\n",
        "        bn5   = BatchNormalization()(conv5)\n",
        "        act5  = Activation(\"relu\")(bn5)\n",
        "        \n",
        "        conv6 = SeparableConv2D(256, (3, 3), padding=\"same\")(act5)\n",
        "        bn6   = BatchNormalization()(conv6)\n",
        "        act6  = Activation(\"relu\")(bn6)\n",
        "        \n",
        "        conv7 = Conv2D(nb_classes, (1, 1), padding=\"same\")(act6)\n",
        "        bn7   = BatchNormalization()(conv7)\n",
        "        act7  = Activation(\"relu\")(bn7)\n",
        "        \n",
        "        gap = GlobalAveragePooling2D()(act7)\n",
        "        final = Activation(\"softmax\")(gap)\n",
        "        \n",
        "        return Model(inputs=inp, outputs=final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta-JIf4xe6-k",
        "colab_type": "code",
        "outputId": "e8f39bed-bca1-43be-9c7a-ab6d5eea78c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1219
        }
      },
      "source": [
        "inp = Input(shape=(32, 32, 3))\n",
        "net = AdequatelyDesignedAllCNNLike().make(inp, 100)\n",
        "net.compile(SGD(lr=0.01, decay=0.001, momentum=0.8), \"categorical_crossentropy\",\n",
        "             metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
        "\n",
        "\n",
        "print(net.summary())\n",
        "\n",
        "net.fit_generator(train_gen, steps_per_epoch=50000 // BATCH_SIZE, epochs=5)\n",
        "loss, acc, topk_acc = net.evaluate_generator(test_gen, steps=10000 // BATCH_SIZE)\n",
        "\n",
        "print(f\"Accuracy: {acc}, Top5 Accuracy {topk_acc} and Loss {loss}.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 32, 32, 96)        2688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_76 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_86 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 32, 32, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_77 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_87 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 16, 16, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_78 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_88 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_31 (Separab (None, 16, 16, 256)       25696     \n",
            "_________________________________________________________________\n",
            "batch_normalization_79 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 8, 8, 192)         442560    \n",
            "_________________________________________________________________\n",
            "batch_normalization_80 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_32 (Separab (None, 8, 8, 256)         51136     \n",
            "_________________________________________________________________\n",
            "batch_normalization_81 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 8, 8, 100)         25700     \n",
            "_________________________________________________________________\n",
            "batch_normalization_82 (Batc (None, 8, 8, 100)         400       \n",
            "_________________________________________________________________\n",
            "activation_92 (Activation)   (None, 8, 8, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_93 (Activation)   (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 718,228\n",
            "Trainable params: 716,044\n",
            "Non-trainable params: 2,184\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 3.9868 - categorical_accuracy: 0.1228 - top_k_categorical_accuracy: 0.3403\n",
            "Epoch 2/5\n",
            "1562/1562 [==============================] - 27s 17ms/step - loss: 3.5641 - categorical_accuracy: 0.2048 - top_k_categorical_accuracy: 0.4845\n",
            "Epoch 3/5\n",
            "1562/1562 [==============================] - 27s 17ms/step - loss: 3.3172 - categorical_accuracy: 0.2514 - top_k_categorical_accuracy: 0.5502\n",
            "Epoch 4/5\n",
            "1562/1562 [==============================] - 27s 17ms/step - loss: 3.1535 - categorical_accuracy: 0.2869 - top_k_categorical_accuracy: 0.5952\n",
            "Epoch 5/5\n",
            "1562/1562 [==============================] - 27s 17ms/step - loss: 3.0230 - categorical_accuracy: 0.3106 - top_k_categorical_accuracy: 0.6253\n",
            "Accuracy: 0.3067817014446228, Top5 Accuracy 0.6074438202247191 and Loss 2.949973174121177.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncz_LGTtxURM",
        "colab_type": "text"
      },
      "source": [
        "## Final notes\n",
        "\n",
        "As you can see, it is indeed possible with slight alterations to speed up a convolutional network like All-CNN-C by ~7% (See Wide Standard Convolution) with small drop in accuracy.\n",
        "Moreover, with a better-designed network (See AdequatelyDesignedAllCNNLike model), the speedup is considerable (~ 20%) and the accuracy drop is still small!\n",
        "\n",
        "Anyway, remember that there's no silver bullet and you should always experiment in order to get satisfying results.\n",
        "\n",
        "Hopefully, the methods showed above and described in the blog post will help."
      ]
    }
  ]
}